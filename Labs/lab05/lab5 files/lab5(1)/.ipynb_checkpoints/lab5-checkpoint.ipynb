{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "pandas is an open source Python library for data analysis. Python has always been great for prepping and munging data, but it's never been great for analysis - you'd usually end up using R or loading it into a database and using SQL (or worse, Excel). pandas makes Python great for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "pandas introduces two new data structures to Python - Series and DataFrame, both of which are built on top of NumPy (this means it's fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "A Series is a one-dimensional object similar to an array, list, or column in a table. It will assign a labeled index to each item in the Series. By default, each item will receive an index label from 0 to N, where N is the length of the Series minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                7\n",
       "1       Heisenberg\n",
       "2             3.14\n",
       "3      -1789710578\n",
       "4    Happy Eating!\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series with an arbitrary list\n",
    "s = pd.Series([7, 'Heisenberg', 3.14, -1789710578, 'Happy Eating!'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify an index to use when creating the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                7\n",
       "Z       Heisenberg\n",
       "C             3.14\n",
       "Y      -1789710578\n",
       "E    Happy Eating!\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([7, 'Heisenberg', 3.14, -1789710578, 'Happy Eating!'],\n",
    "              index=['A', 'Z', 'C', 'Y', 'E'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series constructor can convert a dictonary as well, using the keys of the dictionary as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago          1000.0\n",
       "New York         1300.0\n",
       "Portland          900.0\n",
       "San Francisco    1100.0\n",
       "Austin            450.0\n",
       "Boston              NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Chicago': 1000, 'New York': 1300, 'Portland': 900, 'San Francisco': 1100,\n",
    "     'Austin': 450, 'Boston': None}\n",
    "s = pd.Series(d)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the index to select specific items from the Series ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just Chicago\n",
    "s[\"Chicago\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago          1000.0\n",
       "Portland          900.0\n",
       "San Francisco    1100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Chicago, Portland & San Francisco\n",
    "s[[\"Chicago\", \"Portland\", \"San Francisco\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use boolean indexing for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Portland    900.0\n",
       "Austin      450.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just get cities with less than 1000\n",
    "s[s < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last one might be a little weird, so let's make it more clear - cities < 1000 returns a Series of True/False values, which we then pass to our Series cities, returning the corresponding True items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago          False\n",
      "New York         False\n",
      "Portland          True\n",
      "San Francisco    False\n",
      "Austin            True\n",
      "Boston           False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "Portland    900.0\n",
      "Austin      450.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "less_than_1000 = s < 1000\n",
    "print(less_than_1000)\n",
    "print('\\n')\n",
    "print(s[less_than_1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the values in a Series on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old value: 1000.0\n",
      "New value: 400.0\n"
     ]
    }
   ],
   "source": [
    "# changing based on the index\n",
    "print('Old value:', s['Chicago'])\n",
    "s[\"Chicago\"] = 400\n",
    "print('New value:', s['Chicago'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago     400.0\n",
      "Portland    900.0\n",
      "Austin      450.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Chicago     750.0\n",
      "Portland    750.0\n",
      "Austin      750.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# changing values using boolean logic\n",
    "print(s[s < 1000])\n",
    "print('\\n')\n",
    "s[s < 1000] = 750\n",
    "print(s[s < 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you aren't sure whether an item is in the Series? You can check using idiomatic Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if Seattle in the city list\n",
    "print('Seattle' in s)\n",
    "# Check if San Francisco in the city list\n",
    "print('San Francisco' in s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations can be done using scalars and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago          250.000000\n",
       "New York         433.333333\n",
       "Portland         250.000000\n",
       "San Francisco    366.666667\n",
       "Austin           250.000000\n",
       "Boston                  NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide city values by 3\n",
    "s / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago           562500.0\n",
       "New York         1690000.0\n",
       "Portland          562500.0\n",
       "San Francisco    1210000.0\n",
       "Austin            562500.0\n",
       "Boston                 NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square city values\n",
    "s ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL checking can be performed with isnull and notnull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago          False\n",
      "New York         False\n",
      "Portland         False\n",
      "San Francisco    False\n",
      "Austin           False\n",
      "Boston            True\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "Boston   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# use boolean logic to grab the NULL cities\n",
    "print(s.isnull())\n",
    "print('\\n')\n",
    "print(s[s.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "A DataFrame is a tablular data structure comprised of rows and columns, akin to a spreadsheet, database table, or R's data.frame object. You can also think of a DataFrame as a group of Series objects that share an index (the column names).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "To create a DataFrame out of common Python data structures, we can pass a dictionary of lists to the DataFrame constructor.\n",
    "\n",
    "Using the columns parameter allows us to tell the constructor how we'd like the columns ordered. By default, the DataFrame constructor will order the columns alphabetically (though this isn't the case when reading from a file - more on that next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Bears</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>Bears</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>Bears</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Packers</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>Packers</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>Lions</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011</td>\n",
       "      <td>Lions</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>Lions</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     team  wins  losses\n",
       "0  2010    Bears    11       5\n",
       "1  2011    Bears     8       8\n",
       "2  2012    Bears    10       6\n",
       "3  2011  Packers    15       1\n",
       "4  2012  Packers    11       5\n",
       "5  2010    Lions     6      10\n",
       "6  2011    Lions    10       6\n",
       "7  2012    Lions     4      12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'year': [2010, 2011, 2012, 2011, 2012, 2010, 2011, 2012],\n",
    "        'team': ['Bears', 'Bears', 'Bears', 'Packers', 'Packers', 'Lions', 'Lions', 'Lions'],\n",
    "        'wins': [11, 8, 10, 15, 11, 6, 10, 4],\n",
    "        'losses': [5, 8, 6, 1, 5, 10, 6, 12]}\n",
    "football = pd.DataFrame(data)\n",
    "#football = pd.DataFrame(data, columns=['year', 'team', 'wins', 'losses'])\n",
    "football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV\n",
    "\n",
    "Reading a CSV is as simple as calling the read_csv function. By default, the read_csv function expects the column separator to be a comma, but you can change that using the sep parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Lg</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>GF</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SV</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>R</th>\n",
       "      <th>ER</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>IBB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HBP</th>\n",
       "      <th>BK</th>\n",
       "      <th>WP</th>\n",
       "      <th>BF</th>\n",
       "      <th>ERA+</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>H/9</th>\n",
       "      <th>HR/9</th>\n",
       "      <th>BB/9</th>\n",
       "      <th>SO/9</th>\n",
       "      <th>SO/BB</th>\n",
       "      <th>Awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>25</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>5.51</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>84</td>\n",
       "      <td>1.507</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>26</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727</td>\n",
       "      <td>2.09</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>107.2</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>240</td>\n",
       "      <td>0.994</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.82</td>\n",
       "      <td>CYA-3MVP-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>27</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>71.2</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>239</td>\n",
       "      <td>1.186</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.40</td>\n",
       "      <td>ASMVP-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Age   Tm  Lg  W  L   W-L%   ERA   G  GS  GF  CG  SHO  SV     IP   H  \\\n",
       "0  1995   25  NYY  AL  5  3  0.625  5.51  19  10   2   0    0   0   67.0  71   \n",
       "1  1996   26  NYY  AL  8  3  0.727  2.09  61   0  14   0    0   5  107.2  73   \n",
       "2  1997   27  NYY  AL  6  4  0.600  1.88  66   0  56   0    0  43   71.2  65   \n",
       "\n",
       "    R  ER  HR  BB  IBB   SO  HBP  BK  WP   BF  ERA+   WHIP  H/9  HR/9  BB/9  \\\n",
       "0  43  41  11  30    0   51    2   1   0  301    84  1.507  9.5   1.5   4.0   \n",
       "1  25  25   1  34    3  130    2   0   1  425   240  0.994  6.1   0.1   2.8   \n",
       "2  17  15   5  20    6   68    0   0   2  301   239  1.186  8.2   0.6   2.5   \n",
       "\n",
       "   SO/9  SO/BB       Awards  \n",
       "0   6.9   1.70          NaN  \n",
       "1  10.9   3.82  CYA-3MVP-12  \n",
       "2   8.5   3.40     ASMVP-25  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_csv = pd.read_csv('mariano-rivera.csv')\n",
    "from_csv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file had headers, which the function inferred upon reading in the file. Had we wanted to be more explicit, we could have passed header=None to the function along with a list of column names to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with DataFrames\n",
    "Now that we can get data into a DataFrame, we can finally start working with them. pandas has an abundance of functionality, far too much for me to cover in this introduction. I'd encourage anyone interested in diving deeper into the library to check out its excellent documentation. Or just use Google - there are a lot of Stack Overflow questions and blog posts covering specifics of the library.\n",
    "\n",
    "We'll be using the MovieLens dataset in many examples going forward. The dataset contains 100,000 ratings made by 600 users on 9,000 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/3384481262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mr_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unix_timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rating.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('users.csv', header = None, names = u_cols)\n",
    "users.head()\n",
    "\n",
    "\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv('movies.csv', header = None, names = m_cols, usecols = range(5))\n",
    "movies['movie_id'] = pd.to_numeric(movies['movie_id'], errors = 'coerce').fillna(1)\n",
    "movies.head()\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('rating.csv', header = None, name = r_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "pandas has a variety of functions for getting basic information about your DataFrame, the most basic of which is using the info method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/167274070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells a few things about our DataFrame.\n",
    "\n",
    "It's obviously an instance of a DataFrame.\n",
    "Each row was assigned an index of 0 to N-1, where N is the number of rows in the DataFrame. pandas will do this by default if an index is not specified. Don't worry, this can be changed later.\n",
    "There are 1,682 rows (every row must have an index).\n",
    "Our dataset has five total columns, one of which isn't populated at all (video_release_date) and two that are missing some values (release_date and imdb_url).\n",
    "The last datatypes of each column, but not necessarily in the corresponding order to the listed columns. You should use the dtypes method to get the datatype for each column.\n",
    "An approximate amount of RAM used to hold the DataFrame. See the .memory_usage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame's also have a describe method, which is great for seeing basic statistics about the dataset's numeric columns. Be careful though, since this will return information on all columns of a numeric datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users[['age']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly see the average age of our users is just above 34 years old, with the youngest being 7 and the oldest being 73. The median age is 31, with the youngest quartile of users being 25 or younger, and the oldest quartile being at least 43.\n",
    "\n",
    "You've probably noticed that I've used the head method regularly throughout this post - by default, head displays the first five records of the dataset, while tail displays the last five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .unique() function to get all the unique entries in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technician', 'other', 'writer', 'executive', 'administrator',\n",
       "       'student', 'lawyer', 'educator', 'scientist', 'entertainment',\n",
       "       'programmer', 'librarian', 'homemaker', 'artist', 'engineer',\n",
       "       'marketing', 'none', 'healthcare', 'retired', 'salesman', 'doctor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['occupation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting\n",
    "You can think of a DataFrame as a group of Series that share an index (in this case the column headers). This makes it easy to select specific columns.\n",
    "\n",
    "Selecting a single column from the DataFrame will return a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    technician\n",
       "1         other\n",
       "2        writer\n",
       "3    technician\n",
       "4         other\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['occupation'].head()\n",
    "#users[['occupation']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns, simply pass a list of column names to the DataFrame, the output of which will be a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age zip_code\n",
      "0   24    85711\n",
      "1   53    94043\n",
      "2   23    32067\n",
      "3   24    43537\n",
      "4   33    15213\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(users[['age', 'zip_code']].head())\n",
    "print('\\n')\n",
    "\n",
    "# can also store in a variable to use later\n",
    "columns_you_want = ['occupation', 'gender'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row selection can be done multiple ways, but doing so by an individual index or boolean indexing are typically easiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (485761633.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/485761633.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print('\\n')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# users older than 25\n",
    "print(users[users['age'] > 25])\n",
    "print('\\n')\n",
    "\n",
    "# users aged 40 AND male\n",
    "print(users[(users['age'] == 40) & (users['gender' == 'M'])\n",
    "print('\\n')\n",
    "\n",
    "# users younger than 30 OR female\n",
    "print(users[(users['age'] < 30) & (users['gender' == 'F')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining\n",
    "Throughout an analysis, we'll often need to merge/join datasets as data is typically stored in a relational manner.\n",
    "\n",
    "Our MovieLens data is a good example of this - a rating requires both a user and a movie, and the datasets are linked together by a key - in this case, the user_id and movie_id. It's possible for a user to be associated with zero or many ratings and movies. Likewise, a movie can be rated zero or many times, by a number of different users.\n",
    "\n",
    "Like SQL's JOIN clause, pandas.merge allows two DataFrames to be joined on one or more keys. The function provides a series of parameters (on, left_on, right_on, left_index, right_index) allowing you to specify the columns or indexes on which to join.\n",
    "\n",
    "By default, pandas.merge operates as an inner join, which can be changed using the how parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/576484929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create one merged DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovie_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'users_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "# create one merged DataFrame\n",
    "movie_ratings = pd.merge(movies, ratings, on = 'movie_id')\n",
    "lens = pd.merge(movies_rating, users, on = 'users_id')\n",
    "lens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "Grouping in pandas can taks some time to grasp, but it's pretty awesome once it clicks.\n",
    "\n",
    "pandas groupby method draws largely from the split-apply-combine strategy for data analysis. If you're not familiar with this methodology, I highly suggest you read up on it. It does a great job of illustrating how to properly think through a data problem, which I feel is more important than any technical skill a data analyst/scientist can possess.\n",
    "\n",
    "When approaching a data analysis problem, you'll often break it apart into manageable pieces, perform some operations on each of the pieces, and then put everything back together again (this is the gist split-apply-combine strategy). pandas groupby is great for these problems (R users should check out the plyr and dplyr packages).\n",
    "\n",
    "If you've ever used SQL's GROUP BY or an Excel Pivot Table, you've thought with this mindset, probably without realizing it.\n",
    "\n",
    "We can use this to find the counts of reviews by each movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/319995656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lens' is not defined"
     ]
    }
   ],
   "source": [
    "lens.groupby('title').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take this data and use it to find the top 50 most reviewed movies. We're splitting the DataFrame into groups by movie title and applying the size method to get the count of records in each group. Next we need to order our results in descending order and limit the output to the top 50 using Python's slicing syntax.\n",
    "\n",
    "In SQL, this would be equivalent to:\n",
    "\n",
    "SELECT title, count(1)  \n",
    "FROM lens  \n",
    "GROUP BY title  \n",
    "ORDER BY 2 DESC  \n",
    "LIMIT 50;  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/k788kw6103zdvc0bwpc1lzd00000gn/T/ipykernel_35663/1970000080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmost_rated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmost_rated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lens' is not defined"
     ]
    }
   ],
   "source": [
    "most_rated = lens.groupby('title').size().sort_values(ascending = False)[:50]\n",
    "most_rated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "### Which movies do men and women most disagree on?\n",
    "Think about how you'd have to do this in SQL for a second. You'd have to use a combination of IF/CASE statements with aggregate functions in order to pivot your dataset. Your query would look something like this:\n",
    "\n",
    "SELECT title, AVG(IF(sex = 'F', rating, NULL)), AVG(IF(sex = 'M', rating, NULL))\n",
    "FROM lens\n",
    "GROUP BY title;\n",
    "\n",
    "Imagine how annoying it'd be if you had to do this on more than two columns.\n",
    "\n",
    "DataFrame's have a pivot_table method that makes these kinds of operations much easier (and less verbose).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens.reset_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted = lens.pivot_table(index=['movie_id', 'title'],\n",
    "                           columns=['gender'],\n",
    "                           values='rating',\n",
    "                           fill_value= 0)\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate a difference column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted['diff'] = pivoted['M'] - pivoted['F']\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally just limit to top 50 movies and sort by our difference column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivoted.reset_index('movie_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disagreements = pivoted[pivoted.movie_id.isin(most_50.index)]['diff'].sort_values()\n",
    "disagreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "## Undergrads & Grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the code to read in the global COVID-19 cases, death and recovery time-series data into three separate DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long       Date  Confirmed\n",
       "0            NaN    Afghanistan  33.93911  67.709953  1/22/2020          0\n",
       "1            NaN        Albania  41.15330  20.168300  1/22/2020          0\n",
       "2            NaN        Algeria  28.03390   1.659600  1/22/2020          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long       Date  Deaths\n",
       "0            NaN    Afghanistan  33.93911  67.709953  1/22/2020       0\n",
       "1            NaN        Albania  41.15330  20.168300  1/22/2020       0\n",
       "2            NaN        Algeria  28.03390   1.659600  1/22/2020       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long       Date  Recovered\n",
       "0            NaN    Afghanistan  33.93911  67.709953  1/22/2020          0\n",
       "1            NaN        Albania  41.15330  20.168300  1/22/2020          0\n",
       "2            NaN        Algeria  28.03390   1.659600  1/22/2020          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data into DataFrames\n",
    "cases_df = pd.read_csv('time_series_covid19_confirmed_global_long.csv')\n",
    "deaths_df = pd.read_csv('time_series_covid19_deaths_global_long.csv')\n",
    "recovery_df = pd.read_csv('time_series_covid19_recovered_global_long.csv')\n",
    "\n",
    "\n",
    "# Use display() to show all three DataFrames' heads at once\n",
    "from IPython.display import display\n",
    "\n",
    "display(cases_df.head(3))\n",
    "display(deaths_df.head(3))\n",
    "display(recovery_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows are present in each DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in cases_df: 171585\n",
      "Number of rows in deaths_df: 171585\n",
      "Number of rows in recovery_df: 162360\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows in each DataFrame using len()\n",
    "num_rows_cases = len(cases_df)\n",
    "num_rows_deaths = len(deaths_df)\n",
    "num_rows_recovery = len(recovery_df)\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of rows in cases_df:\", num_rows_cases)\n",
    "print(\"Number of rows in deaths_df:\", num_rows_deaths)\n",
    "print(\"Number of rows in recovery_df:\", num_rows_recovery)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the name of all the columns in the Cases DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in cases_df:\n",
      "Province/State\n",
      "Country/Region\n",
      "Lat\n",
      "Long\n",
      "Date\n",
      "Confirmed\n"
     ]
    }
   ],
   "source": [
    "# Print the names of all columns in the Cases DataFrame\n",
    "print(\"Columns in cases_df:\")\n",
    "for column in cases_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the last 10 rows of the confirmed cases DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Province/State      Country/Region        Lat        Long       Date  \\\n",
      "171575            NaN      United Kingdom  55.378100   -3.436000  9/27/2021   \n",
      "171576            NaN             Uruguay -32.522800  -55.765800  9/27/2021   \n",
      "171577            NaN          Uzbekistan  41.377491   64.585262  9/27/2021   \n",
      "171578            NaN             Vanuatu -15.376700  166.959200  9/27/2021   \n",
      "171579            NaN           Venezuela   6.423800  -66.589700  9/27/2021   \n",
      "171580            NaN             Vietnam  14.058324  108.277199  9/27/2021   \n",
      "171581            NaN  West Bank and Gaza  31.952200   35.233200  9/27/2021   \n",
      "171582            NaN               Yemen  15.552727   48.516388  9/27/2021   \n",
      "171583            NaN              Zambia -13.133897   27.849332  9/27/2021   \n",
      "171584            NaN            Zimbabwe -19.015438   29.154857  9/27/2021   \n",
      "\n",
      "        Confirmed  \n",
      "171575    7701715  \n",
      "171576     388572  \n",
      "171577     172493  \n",
      "171578          4  \n",
      "171579     363300  \n",
      "171580     766051  \n",
      "171581     398946  \n",
      "171582       8988  \n",
      "171583     208867  \n",
      "171584     129919  \n"
     ]
    }
   ],
   "source": [
    "# Show the last 10 rows of the confirmed cases DataFrame\n",
    "last_10_rows_cases = cases_df.tail(10)\n",
    "print(last_10_rows_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a list of unique countries/regions in the deaths data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Countries/Regions in Deaths Data:\n",
      "Afghanistan\n",
      "Albania\n",
      "Algeria\n",
      "Andorra\n",
      "Angola\n",
      "Antigua and Barbuda\n",
      "Argentina\n",
      "Armenia\n",
      "Australia\n",
      "Austria\n",
      "Azerbaijan\n",
      "Bahamas\n",
      "Bahrain\n",
      "Bangladesh\n",
      "Barbados\n",
      "Belarus\n",
      "Belgium\n",
      "Belize\n",
      "Benin\n",
      "Bhutan\n",
      "Bolivia\n",
      "Bosnia and Herzegovina\n",
      "Botswana\n",
      "Brazil\n",
      "Brunei\n",
      "Bulgaria\n",
      "Burkina Faso\n",
      "Burma\n",
      "Burundi\n",
      "Cabo Verde\n",
      "Cambodia\n",
      "Cameroon\n",
      "Canada\n",
      "Central African Republic\n",
      "Chad\n",
      "Chile\n",
      "China\n",
      "Colombia\n",
      "Comoros\n",
      "Congo (Brazzaville)\n",
      "Congo (Kinshasa)\n",
      "Costa Rica\n",
      "Cote d'Ivoire\n",
      "Croatia\n",
      "Cuba\n",
      "Cyprus\n",
      "Czechia\n",
      "Denmark\n",
      "Diamond Princess\n",
      "Djibouti\n",
      "Dominica\n",
      "Dominican Republic\n",
      "Ecuador\n",
      "Egypt\n",
      "El Salvador\n",
      "Equatorial Guinea\n",
      "Eritrea\n",
      "Estonia\n",
      "Eswatini\n",
      "Ethiopia\n",
      "Fiji\n",
      "Finland\n",
      "France\n",
      "Gabon\n",
      "Gambia\n",
      "Georgia\n",
      "Germany\n",
      "Ghana\n",
      "Greece\n",
      "Grenada\n",
      "Guatemala\n",
      "Guinea\n",
      "Guinea-Bissau\n",
      "Guyana\n",
      "Haiti\n",
      "Holy See\n",
      "Honduras\n",
      "Hungary\n",
      "Iceland\n",
      "India\n",
      "Indonesia\n",
      "Iran\n",
      "Iraq\n",
      "Ireland\n",
      "Israel\n",
      "Italy\n",
      "Jamaica\n",
      "Japan\n",
      "Jordan\n",
      "Kazakhstan\n",
      "Kenya\n",
      "Kiribati\n",
      "Korea, South\n",
      "Kosovo\n",
      "Kuwait\n",
      "Kyrgyzstan\n",
      "Laos\n",
      "Latvia\n",
      "Lebanon\n",
      "Lesotho\n",
      "Liberia\n",
      "Libya\n",
      "Liechtenstein\n",
      "Lithuania\n",
      "Luxembourg\n",
      "MS Zaandam\n",
      "Madagascar\n",
      "Malawi\n",
      "Malaysia\n",
      "Maldives\n",
      "Mali\n",
      "Malta\n",
      "Marshall Islands\n",
      "Mauritania\n",
      "Mauritius\n",
      "Mexico\n",
      "Micronesia\n",
      "Moldova\n",
      "Monaco\n",
      "Mongolia\n",
      "Montenegro\n",
      "Morocco\n",
      "Mozambique\n",
      "Namibia\n",
      "Nepal\n",
      "Netherlands\n",
      "New Zealand\n",
      "Nicaragua\n",
      "Niger\n",
      "Nigeria\n",
      "North Macedonia\n",
      "Norway\n",
      "Oman\n",
      "Pakistan\n",
      "Palau\n",
      "Panama\n",
      "Papua New Guinea\n",
      "Paraguay\n",
      "Peru\n",
      "Philippines\n",
      "Poland\n",
      "Portugal\n",
      "Qatar\n",
      "Romania\n",
      "Russia\n",
      "Rwanda\n",
      "Saint Kitts and Nevis\n",
      "Saint Lucia\n",
      "Saint Vincent and the Grenadines\n",
      "Samoa\n",
      "San Marino\n",
      "Sao Tome and Principe\n",
      "Saudi Arabia\n",
      "Senegal\n",
      "Serbia\n",
      "Seychelles\n",
      "Sierra Leone\n",
      "Singapore\n",
      "Slovakia\n",
      "Slovenia\n",
      "Solomon Islands\n",
      "Somalia\n",
      "South Africa\n",
      "South Sudan\n",
      "Spain\n",
      "Sri Lanka\n",
      "Sudan\n",
      "Summer Olympics 2020\n",
      "Suriname\n",
      "Sweden\n",
      "Switzerland\n",
      "Syria\n",
      "Taiwan*\n",
      "Tajikistan\n",
      "Tanzania\n",
      "Thailand\n",
      "Timor-Leste\n",
      "Togo\n",
      "Trinidad and Tobago\n",
      "Tunisia\n",
      "Turkey\n",
      "US\n",
      "Uganda\n",
      "Ukraine\n",
      "United Arab Emirates\n",
      "United Kingdom\n",
      "Uruguay\n",
      "Uzbekistan\n",
      "Vanuatu\n",
      "Venezuela\n",
      "Vietnam\n",
      "West Bank and Gaza\n",
      "Yemen\n",
      "Zambia\n",
      "Zimbabwe\n"
     ]
    }
   ],
   "source": [
    "# Get a list of unique countries/regions in the deaths data\n",
    "unique_countries_deaths = deaths_df['Country/Region'].unique()\n",
    "\n",
    "# Print the list of unique countries/regions\n",
    "print(\"Unique Countries/Regions in Deaths Data:\")\n",
    "for country in unique_countries_deaths:\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge confirmed cases, deaths and recoveries into one DataFrame (Hint: you will need to merge on these 5 columns: ['Province/State', 'Country/Region', 'Date', 'Lat', 'Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long       Date  Confirmed  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953  1/22/2020          0   \n",
       "1            NaN        Albania  41.15330  20.168300  1/22/2020          0   \n",
       "2            NaN        Algeria  28.03390   1.659600  1/22/2020          0   \n",
       "3            NaN        Andorra  42.50630   1.521800  1/22/2020          0   \n",
       "4            NaN         Angola -11.20270  17.873900  1/22/2020          0   \n",
       "\n",
       "   Deaths  Recovered  \n",
       "0       0          0  \n",
       "1       0          0  \n",
       "2       0          0  \n",
       "3       0          0  \n",
       "4       0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>14.058324</td>\n",
       "      <td>108.277199</td>\n",
       "      <td>9/27/2021</td>\n",
       "      <td>766051</td>\n",
       "      <td>18758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158666</th>\n",
       "      <td>NaN</td>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>31.952200</td>\n",
       "      <td>35.233200</td>\n",
       "      <td>9/27/2021</td>\n",
       "      <td>398946</td>\n",
       "      <td>4046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158667</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>15.552727</td>\n",
       "      <td>48.516388</td>\n",
       "      <td>9/27/2021</td>\n",
       "      <td>8988</td>\n",
       "      <td>1703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158668</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>-13.133897</td>\n",
       "      <td>27.849332</td>\n",
       "      <td>9/27/2021</td>\n",
       "      <td>208867</td>\n",
       "      <td>3647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158669</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-19.015438</td>\n",
       "      <td>29.154857</td>\n",
       "      <td>9/27/2021</td>\n",
       "      <td>129919</td>\n",
       "      <td>4607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Province/State      Country/Region        Lat        Long       Date  \\\n",
       "158665            NaN             Vietnam  14.058324  108.277199  9/27/2021   \n",
       "158666            NaN  West Bank and Gaza  31.952200   35.233200  9/27/2021   \n",
       "158667            NaN               Yemen  15.552727   48.516388  9/27/2021   \n",
       "158668            NaN              Zambia -13.133897   27.849332  9/27/2021   \n",
       "158669            NaN            Zimbabwe -19.015438   29.154857  9/27/2021   \n",
       "\n",
       "        Confirmed  Deaths  Recovered  \n",
       "158665     766051   18758          0  \n",
       "158666     398946    4046          0  \n",
       "158667       8988    1703          0  \n",
       "158668     208867    3647          0  \n",
       "158669     129919    4607          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Number of rows in merged_df:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "158670"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns in merged_df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Province/State'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Country/Region'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Lat'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Long'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Date'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Confirmed'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Deaths'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recovered'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge cases_df and deaths_df based on the specified columns\n",
    "merged_df = pd.merge(cases_df, deaths_df, on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long'])\n",
    "\n",
    "# Merge the resulting DataFrame with recovery_df\n",
    "merged_df = pd.merge(merged_df, recovery_df, on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long'])\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "display(merged_df.head())\n",
    "\n",
    "display(merged_df.tail())\n",
    "\n",
    "print('\\n')\n",
    "num_rows_merged = len(merged_df)\n",
    "display(\"Number of rows in merged_df:\", num_rows_merged)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Columns in merged_df:\")\n",
    "for merge_column in merged_df.columns:\n",
    "    display(merge_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame from this merged data for just the latest date (Date equal to '9/27/2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Province/State Country/Region       Lat       Long       Date  \\\n",
      "158412            NaN    Afghanistan  33.93911  67.709953  9/27/2021   \n",
      "158413            NaN        Albania  41.15330  20.168300  9/27/2021   \n",
      "158414            NaN        Algeria  28.03390   1.659600  9/27/2021   \n",
      "158415            NaN        Andorra  42.50630   1.521800  9/27/2021   \n",
      "158416            NaN         Angola -11.20270  17.873900  9/27/2021   \n",
      "\n",
      "        Confirmed  Deaths  Recovered  \n",
      "158412     155072    7200          0  \n",
      "158413     168188    2653          0  \n",
      "158414     202877    5786          0  \n",
      "158415      15189     130          0  \n",
      "158416      55583    1513          0  \n"
     ]
    }
   ],
   "source": [
    "# Filter the merged DataFrame for the latest date\n",
    "latest_date = '9/27/2021'\n",
    "latest_data_df = merged_df[merged_df['Date'] == latest_date]\n",
    "\n",
    "# Print the first few rows of the new DataFrame\n",
    "print(latest_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 5 Countries by deaths on the latest date (Hint: look up sort_values()). Display just the \"Province/State\", \"Country/Region\", and \"Deaths\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Province/State Country/Region  Deaths\n",
      "158645            NaN             US  690426\n",
      "158442            NaN         Brazil  594653\n",
      "158541            NaN          India  447373\n",
      "158577            NaN         Mexico  275676\n",
      "158610            NaN         Russia  201015\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by 'Deaths' column in descending order\n",
    "sorted_df = latest_data_df.sort_values(by='Deaths', ascending=False)\n",
    "\n",
    "# Display only the specified columns: 'Province/State', 'Country/Region', and 'Deaths'\n",
    "top_5_countries_deaths = sorted_df[['Province/State', 'Country/Region', 'Deaths']].head(5)\n",
    "\n",
    "# Print the top 5 countries by deaths on the latest date\n",
    "print(top_5_countries_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new DataFrame of the countries with the top 25 confirmed cases on the latest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Province/State  Country/Region        Lat        Long       Date  \\\n",
      "158645            NaN              US  40.000000 -100.000000  9/27/2021   \n",
      "158541            NaN           India  20.593684   78.962880  9/27/2021   \n",
      "158442            NaN          Brazil -14.235000  -51.925300  9/27/2021   \n",
      "158660            NaN  United Kingdom  55.378100   -3.436000  9/27/2021   \n",
      "158610            NaN          Russia  61.524010  105.318756  9/27/2021   \n",
      "158644            NaN          Turkey  38.963700   35.243300  9/27/2021   \n",
      "158524            NaN          France  46.227600    2.213700  9/27/2021   \n",
      "158543            NaN            Iran  32.427908   53.688046  9/27/2021   \n",
      "158418            NaN       Argentina -38.416100  -63.616700  9/27/2021   \n",
      "158486            NaN        Colombia   4.570900  -74.297300  9/27/2021   \n",
      "158630            NaN           Spain  40.463667   -3.749220  9/27/2021   \n",
      "158547            NaN           Italy  41.871940   12.567380  9/27/2021   \n",
      "158542            NaN       Indonesia  -0.789300  113.921300  9/27/2021   \n",
      "158528            NaN         Germany  51.165691   10.451526  9/27/2021   \n",
      "158577            NaN          Mexico  23.634500 -102.552800  9/27/2021   \n",
      "158606            NaN          Poland  51.919400   19.145100  9/27/2021   \n",
      "158628            NaN    South Africa -30.559500   22.937500  9/27/2021   \n",
      "158647            NaN         Ukraine  48.379400   31.165600  9/27/2021   \n",
      "158605            NaN     Philippines  12.879721  121.774017  9/27/2021   \n",
      "158570            NaN        Malaysia   4.210484  101.975766  9/27/2021   \n",
      "158604            NaN            Peru  -9.190000  -75.015200  9/27/2021   \n",
      "158590            NaN     Netherlands  52.132600    5.291300  9/27/2021   \n",
      "158544            NaN            Iraq  33.223191   43.679291  9/27/2021   \n",
      "158549            NaN           Japan  36.204824  138.252924  9/27/2021   \n",
      "158495            NaN         Czechia  49.817500   15.473000  9/27/2021   \n",
      "\n",
      "        Confirmed  Deaths  Recovered  \n",
      "158645   43116442  690426          0  \n",
      "158541   33697581  447373          0  \n",
      "158442   21366395  594653          0  \n",
      "158660    7701715  136208          0  \n",
      "158610    7334843  201015          0  \n",
      "158644    7066658   63372          0  \n",
      "158524    6827408  114347          0  \n",
      "158543    5547990  119649          0  \n",
      "158418    5251940  114954          0  \n",
      "158486    4952690  126178          0  \n",
      "158630    4951640   86298          0  \n",
      "158547    4662087  130742          0  \n",
      "158542    4209403  141585          0  \n",
      "158528    4209098   93509          0  \n",
      "158577    3635807  275676          0  \n",
      "158606    2903655   75572          0  \n",
      "158628    2897521   87216          0  \n",
      "158647    2503710   59384          0  \n",
      "158605    2490858   37405          0  \n",
      "158570    2209194   25695          0  \n",
      "158604    2173354  199314          0  \n",
      "158590    1997885   18154          0  \n",
      "158544    1996214   22142          0  \n",
      "158549    1696971   17524          0  \n",
      "158495    1689620   30454          0  \n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by 'Confirmed' column in descending order\n",
    "sorted_df_2 = latest_data_df.sort_values(by='Confirmed', ascending=False)\n",
    "\n",
    "# Select the top 25 countries by confirmed cases\n",
    "top_25_countries_confirmed = sorted_df_2.head(25)\n",
    "\n",
    "# Print the new DataFrame with the top 25 countries by confirmed cases\n",
    "print(top_25_countries_confirmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top 10 countries with the highest overall fatality rate of confirmed cases (total deaths divided by total cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Confirmed    Deaths  Fatality Rate\n",
      "Country/Region                                    \n",
      "MS Zaandam           4913      1090       0.221860\n",
      "Yemen             1854834    409887       0.220983\n",
      "Vanuatu               890       160       0.179775\n",
      "Peru            614610886  58915483       0.095858\n",
      "Mexico          813028025  72686321       0.089402\n",
      "Sudan            12121592    825694       0.068118\n",
      "Ecuador         132542843   7868038       0.059362\n",
      "Egypt            84506766   4809672       0.056915\n",
      "China            54999153   2704920       0.049181\n",
      "Somalia           4165835    189802       0.045562\n"
     ]
    }
   ],
   "source": [
    "# Group the data by 'Country/Region' and aggregate total cases and total deaths\n",
    "grouped_df = merged_df.groupby('Country/Region').agg({'Confirmed': 'sum', 'Deaths': 'sum'})\n",
    "\n",
    "# Calculate the fatality rate for each country\n",
    "grouped_df['Fatality Rate'] = grouped_df['Deaths'] / grouped_df['Confirmed']\n",
    "\n",
    "# Sort the DataFrame by the fatality rate in descending order\n",
    "sorted_df_3 = grouped_df.sort_values(by='Fatality Rate', ascending=False)\n",
    "\n",
    "# Select the top 10 countries with the highest fatality rates\n",
    "top_10_countries_fatality = sorted_df_3.head(10)\n",
    "\n",
    "# Print the new DataFrame with the top 10 countries by fatality rate\n",
    "print(top_10_countries_fatality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the top 25 countries on the latest data from above, calculate the difference in their monthly total confirmed cases for September and August 2021 and sort by this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data type of 'Date' column:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country/Region\n",
      "Malaysia          9778615\n",
      "Thailand          9376404\n",
      "Vietnam           7880611\n",
      "Japan             7332155\n",
      "Philippines       6258777\n",
      "Iran              5333146\n",
      "Cuba              4173962\n",
      "Israel            2337011\n",
      "Sri Lanka         1812842\n",
      "Mongolia          1275036\n",
      "Kazakhstan        1141131\n",
      "Morocco            960007\n",
      "Guatemala          943964\n",
      "Australia          821771\n",
      "Azerbaijan         758785\n",
      "Burma              753729\n",
      "United Kingdom     734763\n",
      "Georgia            694815\n",
      "Korea, South       487501\n",
      "Kosovo             448651\n",
      "Botswana           249948\n",
      "Norway             240010\n",
      "Jamaica            234747\n",
      "Benin              223910\n",
      "Mauritius          160641\n",
      "Name: Confirmed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of the 'Date' column\n",
    "date_column_type = merged_df['Date'].dtype\n",
    "\n",
    "# Print the data type\n",
    "display(\"Data type of 'Date' column:\", date_column_type)\n",
    "# dtype('O') means string\n",
    "\n",
    "# Convert the 'Date' column to a datetime data type\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "\n",
    "# Filter the data for August and September 2021\n",
    "start_date = '2021-08-01'\n",
    "end_date = '2021-09-30'\n",
    "\n",
    "date_range_data = merged_df[(merged_df['Date'] >= start_date) & (merged_df['Date'] <= end_date)]\n",
    "\n",
    "# Group the data by 'Country/Region' and aggregate total confirmed cases for each month\n",
    "august_grouped = date_range_data[date_range_data['Date'].dt.month == 8].groupby('Country/Region')['Confirmed'].sum()\n",
    "september_grouped = date_range_data[date_range_data['Date'].dt.month == 9].groupby('Country/Region')['Confirmed'].sum()\n",
    "\n",
    "# Calculate the difference in total confirmed cases between September and August\n",
    "difference_df = september_grouped - august_grouped\n",
    "\n",
    "# Sort the DataFrame by the difference in descending order\n",
    "sorted_difference_df = difference_df.sort_values(ascending=False)\n",
    "\n",
    "# Select the top 25 countries and their differences\n",
    "top_25_difference = sorted_difference_df.head(25)\n",
    "\n",
    "# Print the top 25 countries by the difference in confirmed cases\n",
    "print(top_25_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
